{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    \"\"\"Generates feature input (mfccs, chroma, mel, contrast, tonnetz).\n",
    "    -*- author: mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    X, sample_rate = sf.read(file_name, dtype='float32')\n",
    "    if X.ndim > 1:\n",
    "        X = X[:,0]\n",
    "    X = X.T\n",
    "\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs, chroma, mel, contrast, tonnetz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_audio_files(parent_dir, sub_dirs, file_ext=None, verbose=True):\n",
    "    \"\"\"Parses directory in search of specified file types, then compiles feature data from them.\n",
    "    -*- adapted from code by mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    # by default test for only these types\n",
    "    if file_ext == None:\n",
    "        file_types = ['*.ogg', '*.wav']\n",
    "    else:\n",
    "        file_types = []\n",
    "        file_types.push(file_ext)\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for file_ext in file_types:\n",
    "            # file names\n",
    "            iter = glob.glob(os.path.join(parent_dir, sub_dir, file_ext))\n",
    "            if len(iter) > 0:\n",
    "                if verbose: print('Reading', os.path.join(parent_dir, sub_dir, file_ext), '...')\n",
    "                for fn in tqdm(iter):\n",
    "                    ext_features = get_ext_features(fn)\n",
    "                    if type(ext_features) is np.ndarray:\n",
    "                        features = np.vstack([features, ext_features])\n",
    "                        labels = np.append(labels, label)\n",
    "    return np.array(features), np.array(labels, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext_features(fn):\n",
    "    \"\"\"Returns features for individual audio file.\n",
    "    -*- adapted from code by mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
    "        ext_features = np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
    "        return ext_features\n",
    "    except Exception as e:\n",
    "        print(\"[Error] extract feature error. %s\" % (e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_audio_file(fn):\n",
    "    \"\"\"Returns features of single audio file\n",
    "    -*- adapted from code by mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    features = np.empty((0,193))\n",
    "    ext_features = get_ext_features(fn)\n",
    "    features = np.vstack([features,ext_features])\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(num_classes):\n",
    "    \"\"\"Support vector machine.\n",
    "    -*- ref: mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    return SVC(C=20.0, gamma=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(num_classes):\n",
    "    \"\"\"Multi-layer perceptron.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=193))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(num_classes):\n",
    "    \"\"\"1D Convolutional Neural Network.\n",
    "    -*- ref: panotti https://github.com/drscotthawley/panotti -*-\n",
    "    \"\"\"\n",
    "    from keras.layers import Embedding\n",
    "    from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "    activation = 'softmax' if num_classes > 2 else 'sigmoid'\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, input_shape=(193, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(128, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data_path):\n",
    "    \"\"\"Parses audio files in supplied data path.\n",
    "    -*- author: mtobeiyf https://github.com/mtobeiyf/audio-classification -*-\n",
    "    \"\"\"\n",
    "    r = os.listdir(data_path)\n",
    "    r.sort()\n",
    "    features, labels = parse_audio_files(data_path, r)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, type='cnn', num_classes=None, print_summary=False,\n",
    "    save_model=False, lr=0.01, loss_type=None, epochs=50, optimizer='SGD', verbose=True):\n",
    "    \"\"\"Trains model based on provided feature & target data\n",
    "    Options:\n",
    "    - epochs: The number of iterations. Default is 50.\n",
    "    - lr: Learning rate. Increase to speed up training time, decrease to get more accurate results (if your loss is 'jumping'). Default is 0.01.\n",
    "    - optimiser: Default is 'SGD'.\n",
    "    - print_summary: Prints a summary of the model you'll be training. Default is False.\n",
    "    - loss_type: Classification type. Default is categorical for >2 classes, and binary otherwise.\n",
    "    \"\"\"\n",
    "    print(\"SA MODEL MUNIR\")\n",
    "    labels = labels.ravel()\n",
    "    if num_classes == None: num_classes = np.max(labels, axis=0)\n",
    "\n",
    "    model = cnn(num_classes)\n",
    "    if print_summary == True: model.summary()\n",
    "\n",
    "    if loss_type == None:\n",
    "        loss_type = 'binary' if num_classes <= 2 else 'categorical'\n",
    "    \n",
    "    print(\"*****\")\n",
    "    print(loss_type)\n",
    "    print(\"*****\")\n",
    "    model.compile(optimizer=SGD(lr=lr),\n",
    "                  loss='%s_crossentropy' % loss_type,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if loss_type == 'categorical':\n",
    "        y = to_categorical(labels - 1, num_classes=num_classes)\n",
    "    else:\n",
    "        y = labels - 1\n",
    "\n",
    "    x = np.expand_dims(features, axis=2)\n",
    "\n",
    "    model.fit(x, y, batch_size=64, epochs=epochs, verbose=verbose)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_path):\n",
    "    \"\"\"Trains model based on provided feature & target data\n",
    "    Options:\n",
    "    - epochs: The number of iterations. Default is 50.\n",
    "    - lr: Learning rate. Increase to speed up training time, decrease to get more accurate results (if your loss is 'jumping'). Default is 0.01.\n",
    "    - optimiser: Default is 'SGD'.\n",
    "    - print_summary: Prints a summary of the model you'll be training. Default is False.\n",
    "    - type: Classification type. Default is categorical for >2 classes, and binary otherwise.\n",
    "    \"\"\"\n",
    "    x_data = parse_audio_file(data_path)\n",
    "    X_train = np.expand_dims(x_data, axis=2)\n",
    "    pred = model.predict(X_train)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaderboard(pred, data_path):\n",
    "    \"\"\"Pretty prints leaderboard of top matches\n",
    "    \"\"\"\n",
    "    r = os.listdir(data_path)\n",
    "    r.sort()\n",
    "    sorted = np.argsort(pred)\n",
    "    count = 0\n",
    "    for index in (-pred).argsort()[0]:\n",
    "        print('%d.' % (count + 1), r[index + 1], str(round(pred[0][index]*100)) + '%', '(index %s)' % index)\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/munir/Desktop/pyAudioClassification-master/example/data/101 - Dog/*.ogg ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:36<00:00,  1.06it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/munir/Desktop/pyAudioClassification-master/example/data/102 - Rooster/*.ogg ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:31<00:00,  1.21it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/munir/Desktop/pyAudioClassification-master/example/data/103 - Pig/*.ogg ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:35<00:00,  1.09it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/munir/Desktop/pyAudioClassification-master/example/data/104 - Cow/*.ogg ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:35<00:00,  1.22it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/munir/Desktop/pyAudioClassification-master/example/data/105 - Frog/*.ogg ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:41<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "features, labels = feature_extraction('/home/munir/Desktop/pyAudioClassification-master/example/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA MODEL MUNIR\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 191, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 191, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 189, 64)           12352     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 189, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 63, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 61, 128)           24704     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 61, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 59, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 87,108\n",
      "Trainable params: 87,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "*****\n",
      "categorical\n",
      "*****\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4958 - acc: 0.3600\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 501us/step - loss: 1.4522 - acc: 0.2750\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 457us/step - loss: 1.4853 - acc: 0.3200\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 477us/step - loss: 1.5334 - acc: 0.3500\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 479us/step - loss: 1.5380 - acc: 0.2850\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 470us/step - loss: 1.5549 - acc: 0.3500\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 478us/step - loss: 1.5621 - acc: 0.3000\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 481us/step - loss: 1.4796 - acc: 0.3150\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 479us/step - loss: 1.4230 - acc: 0.3550\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 500us/step - loss: 1.4669 - acc: 0.3650\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 545us/step - loss: 1.4852 - acc: 0.2900\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 457us/step - loss: 1.4627 - acc: 0.2900\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 505us/step - loss: 1.5645 - acc: 0.3200\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 452us/step - loss: 1.4863 - acc: 0.3050\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 477us/step - loss: 1.4147 - acc: 0.3300\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 477us/step - loss: 1.4753 - acc: 0.3550\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 491us/step - loss: 1.4866 - acc: 0.3150\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 493us/step - loss: 1.4694 - acc: 0.3100\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 480us/step - loss: 1.4206 - acc: 0.3300\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 477us/step - loss: 1.3959 - acc: 0.3500\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 514us/step - loss: 1.4434 - acc: 0.3450\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 518us/step - loss: 1.4591 - acc: 0.3250\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 602us/step - loss: 1.4842 - acc: 0.3000\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 663us/step - loss: 1.4999 - acc: 0.3750\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 551us/step - loss: 1.4478 - acc: 0.3250\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 469us/step - loss: 1.4630 - acc: 0.3250\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 458us/step - loss: 1.4694 - acc: 0.2750\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 502us/step - loss: 1.4189 - acc: 0.3600\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 496us/step - loss: 1.4834 - acc: 0.3050\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 529us/step - loss: 1.4861 - acc: 0.3200\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 559us/step - loss: 1.4506 - acc: 0.3200\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 510us/step - loss: 1.4836 - acc: 0.3250\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 512us/step - loss: 1.4931 - acc: 0.3050\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 489us/step - loss: 1.4616 - acc: 0.2750\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 515us/step - loss: 1.4543 - acc: 0.2800\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 512us/step - loss: 1.3988 - acc: 0.2700\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 495us/step - loss: 1.5189 - acc: 0.2700\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 480us/step - loss: 1.4394 - acc: 0.3200\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 470us/step - loss: 1.4379 - acc: 0.3050\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 490us/step - loss: 1.4710 - acc: 0.2850\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 478us/step - loss: 1.4139 - acc: 0.3000\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 478us/step - loss: 1.5177 - acc: 0.2850\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 533us/step - loss: 1.4189 - acc: 0.2500\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 477us/step - loss: 1.3824 - acc: 0.4000\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 499us/step - loss: 1.4457 - acc: 0.2950\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 487us/step - loss: 1.4121 - acc: 0.3400\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 486us/step - loss: 1.4127 - acc: 0.3150\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 512us/step - loss: 1.4270 - acc: 0.3100\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 492us/step - loss: 1.4231 - acc: 0.2950\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 474us/step - loss: 1.4167 - acc: 0.3450\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 508us/step - loss: 1.4005 - acc: 0.3600\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 455us/step - loss: 1.3836 - acc: 0.2950\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 472us/step - loss: 1.4081 - acc: 0.3150\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 501us/step - loss: 1.4555 - acc: 0.2800\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 475us/step - loss: 1.4449 - acc: 0.2700\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 486us/step - loss: 1.4308 - acc: 0.2800\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 500us/step - loss: 1.4557 - acc: 0.2750\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 519us/step - loss: 1.4297 - acc: 0.3000\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 485us/step - loss: 1.4469 - acc: 0.2450\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 507us/step - loss: 1.4464 - acc: 0.2950\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 491us/step - loss: 1.4091 - acc: 0.2600\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 488us/step - loss: 1.4282 - acc: 0.2900\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 496us/step - loss: 1.4199 - acc: 0.3200\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 492us/step - loss: 1.4795 - acc: 0.2750\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 490us/step - loss: 1.4212 - acc: 0.3000\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 595us/step - loss: 1.4552 - acc: 0.3250\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 618us/step - loss: 1.4641 - acc: 0.2700\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 626us/step - loss: 1.4417 - acc: 0.3100\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 686us/step - loss: 1.4006 - acc: 0.3400\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 655us/step - loss: 1.4358 - acc: 0.3400\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 577us/step - loss: 1.3903 - acc: 0.3550\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 685us/step - loss: 1.4616 - acc: 0.2450\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 482us/step - loss: 1.4436 - acc: 0.2750\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 434us/step - loss: 1.4583 - acc: 0.2700\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 482us/step - loss: 1.4658 - acc: 0.3250\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 518us/step - loss: 1.4035 - acc: 0.3000\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 516us/step - loss: 1.4305 - acc: 0.3350\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 606us/step - loss: 1.4056 - acc: 0.3350\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 570us/step - loss: 1.3919 - acc: 0.3400\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 557us/step - loss: 1.4295 - acc: 0.2850\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 586us/step - loss: 1.4488 - acc: 0.3100\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 560us/step - loss: 1.4118 - acc: 0.3050\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 523us/step - loss: 1.4634 - acc: 0.3050\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 459us/step - loss: 1.4766 - acc: 0.2850\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 512us/step - loss: 1.4101 - acc: 0.2700\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 498us/step - loss: 1.4293 - acc: 0.3000\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 516us/step - loss: 1.4683 - acc: 0.3400\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 534us/step - loss: 1.3977 - acc: 0.3450\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 517us/step - loss: 1.4128 - acc: 0.3050\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 558us/step - loss: 1.4839 - acc: 0.3100\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 512us/step - loss: 1.3743 - acc: 0.2950\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 489us/step - loss: 1.4439 - acc: 0.2750\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 460us/step - loss: 1.4066 - acc: 0.3000\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 495us/step - loss: 1.3915 - acc: 0.3150\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 514us/step - loss: 1.3811 - acc: 0.2800\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 533us/step - loss: 1.4704 - acc: 0.2500\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 483us/step - loss: 1.4063 - acc: 0.2750\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 593us/step - loss: 1.4140 - acc: 0.3100\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 585us/step - loss: 1.4275 - acc: 0.2900\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 590us/step - loss: 1.4042 - acc: 0.3150\n"
     ]
    }
   ],
   "source": [
    "model=train(features, labels,lr=0.0001,epochs=100,print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 104 - Cow 54.0% (index 2)\n",
      "2. 105 - Frog 31.0% (index 3)\n",
      "3. 103 - Pig 12.0% (index 1)\n",
      "4. 102 - Rooster 3.0% (index 0)\n"
     ]
    }
   ],
   "source": [
    "pred = predict(model, '/home/munir/Desktop/pyAudioClassification-master/example/cow_test.wav')\n",
    "print_leaderboard(pred, '/home/munir/Desktop/pyAudioClassification-master/example/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
